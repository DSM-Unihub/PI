% Nesta seção, você deverá realizar um mapeamento de toda a produção acadêmica sobre o tema do seu projeto. É um processo bastante importante porque reúnem todas as pesquisas e descrevem as conclusões das pesquisas sobre o tema \cite{smith:99}. Para escrever um bom estado da arte, você poderá utilizar algumas perguntas norteadoras, tais como:

% \begin{enumerate}
%     \item O que as atuais pesquisas científicas concluíram sobre o tema?
%     \item Quais as divergências dos pesquisadores sobre o assunto?
%     \item Quem está pesquisando sobre esse tema?
%     \item Onde estão fazendo essas pesquisas?
% \end{enumerate}

% Em outras palavras, o estado da arte destaca os aspectos de outras pesquisas, mas também identifica as lacunas que existem nessas pesquisas. Ou seja: analisa o que as pesquisas falaram e o que não falaram sobre o tema \cite{Alencar2007,Beltrano2021,Fulano2021}.

% Segundo \textcite{Ramos2003,Carvalho2004}, para que você possa descrever as pesquisas/trabalhos que estão relacionados ao seu, não esqueça de citá-los ao decorrer do texto. Para isso, você poderá utilizar o comando $\backslash$cite para citação implícita ou o comando $\backslash$textcite para citações explícitas.

% As citações diretas curtas (de até três linhas) acompanham o corpo do texto e se destacam com aspas duplas. Caso o texto original já contenha aspas, estas devem ser substituídas por aspas simples. Enquanto que, para representar as citações diretas longas (com mais de três linhas), estas devem ser transcritas em parágrafo distinto, da seguinte forma:

% \begin{displayquote}
%    Toda citação direta com mais de três linhas é considerada uma citação direta longa.
% Este tipo de citação deve ser escrita sem aspas, em parágrafo distinto, com fonte de tamanho 10, espaçamento simples e com recuo de 4cm da margem esquerda, terminando na margem direita, conforme ilustrado neste exemplo \cite{Andujar2006}.
% \end{displayquote}

% Vale ressaltar que a utilização de citações diretas longas deve ser evitada durante a escrita de artigos científicos. Conforme visto em \textcite{Kalakota2002,Purcidonio2008}, os dados de cada referência podem ser obtidos de um arquivo com a extensão bib, geralmente na própria página de \textit{download} da referência (artigos, livros, etc.) ou, ainda, a partir do Google Acadêmico, etc.

%%%%COMEÇA AQUI!!

O estudo realizado em \textcite{pitropakis2020monitoring}, teve como foco o combate ao discurso de ódio contra imigrantes, por ser um grande problema na América do norte e em regiões Europeias. Foi desenvolvido um programa que utiliza PLN para identificar postagens xenofóbicas na plataforma X (anteriormente chamada Twitter), por ser muito utilizada para escrever e compartilhar pequenos textos opinativos, característica que abre espaço para muitas postagens preconceituosas e agressivas. A composição do conjunto de dados foi feita utilizando a API pública do Twitter, que disponibiliza dados públicos gerados por usuários, por onde foram coletadas diversas postagens feitas em inglês nos EUA, Canadá e Reino Unido, que continham mensagem anti-imigrante e/ou xenofóbica. Foram obtidas 8270 postagens, manualmente separadas em negativas, não negativas, indeciso e não relacionado.

Após o tratamento dos dados, optou-se pela utilização de alguns algoritmos comumente empregados em classificação de texto, como Support Vector Machines (SVM), Naïve–Bayes (NB), e Logistic Regression (LR), sendo os três testados para escolher o mais adequado. Estes performam bem se empregados na detecção de postagens com discursos de ódio, detecção de linguagem abusiva. Além da capacidade de encontrar as palavras mais frequentes entre os tweets, o modelo obteve uma precisão de 87\% na classificação de conteúdo xenofóbico, com a técnica LR aplicada a N-gramas com palavras. N-gramas são sequências de palavras, portanto, um algoritmo que trabalhe com elas poderá calcular a probabilidade da palavra seguinte em uma frase, a partir de um conjunto de dados com diversas frases. É a mesma metodologia utilizada nos \textit{browsers}, para autocompletar pesquisas antes que o usuário termine de digitar \textcite{srinidhi2019understanding}. No caso de \textcite{pitropakis2020monitoring}, as frases com probabilidades semelhantes indicam contextos semelhantes, possibilitando a classificação das frases.

Dos desafios encontrados no desenvolvimento, destacam-se a dificuldade na definição do que é xenofobia, pois trata-se de um termo muito amplo, sendo um tipo de preconceito que pode ser direcionado a diversos povos diferentes. A partir disso, surgem inúmeros xingamentos e injúrias relacionados à cultura ou peculiaridades de um povo. Portanto, o foco foi em termos mais abrangentes, como imigrante, imigração e refugiados, o que, certamente deixou de fora muitas postagens mal-intencionadas. Houve dificuldade também em capturar o sentimento negativo referente aos imigrantes, pois em uma postagem, ele pode se apresentar de diversas maneiras, sendo mais aparentes com o uso de palavrões, ou mais discretas, como é o caso de comentários sarcásticos, que necessitariam de um treinamento específico para reconhecê-los. Em sua metodologia, este monitoramento de comentários anti-imigrantes assemelha-se muito à proposta deste projeto, portanto, estas mesmas dificuldades são consideradas no desenvolvimento do sistema ReSist.

Em \textcite{de2017offensive}, a verificação é ainda mais ampla, pois o projeto tem como objetivo a detecção de comentários ofensivos na \textit{Web} brasileira. Além das dificuldades de se trabalhar com um conceito tão abrangente, o autor também pontua que muitos usuários disfarçam palavras ofensivas trocando letras por números ou símbolos, portanto, a simples criação de uma lista de bloqueio poderia deixar de fora muitos comentários, daí surge a necessidade de um conjunto de dados com exemplos positivos e negativos. Este conjunto foi criado utilizando como base o site de notícias G1, que por ser o mais acessado do país, possui muitos comentários em suas notícias. Verificou-se que em cerca de 90\% das notícias analisadas, havia pelo menos um comentário ofensivo. Com a implementação de um \textit{Webscraper}, um software para coletar dados de sites, foram extraídas 115 notícias, com 10,366 comentários. Destes, foram selecionados 1,250 comentários, a serem classificados como ofensivos ou não, e em caso afirmativo, classificados como racismo, sexismo, homofobia, xenofobia, intolerância religiosa ou palavrões. Para a classificação foi desenvolvida uma ferramenta \textit{Web} que exibe o comentário, o link da notícia e as opções de classificação, o que agilizou todo o processo.

A seguir, são tomadas algumas medidas de pré-processamento, como o \textit{case folding}, que consiste em converter todas as letras para o mesmo tipo de caixa, no caso, caixa baixa, e a conversão em n-gramas, usando unigramas, bigramas e trigramas (1 palavra ou sequências de 2 e 3, respectivamente), para capturar a estrutura do comentário odioso. Foi testada também a técnica de seleção de \textit{features}, que é o processo de redução do número de variáveis de entrada no desenvolvimento de um modelo preditivo. Buscando remover variáveis que podem retardar o desenvolvimento e treinamento do modelo, reduzindo custo computacional e melhorando desempenho, em alguns casos. \textcite{de2017offensive} também utiliza os Algoritmos de Naive Bayes e SVM.

O modelo foi avaliado a partir do F-score,  calculado a partir da medida de resultados falsos-positivos (precisão, ou PPV), e falsos-negativos(revocação, ou \textit{recall}) \textcite{avaliacao-modelo}. O melhor desempenho obtido foi de .85, utilizando SVM. Os pesquisadores comentam que o contexto é essencial para a classificação, pois em diversos casos, as mesmas palavras que compõem um comentário ofensivo, não seriam ofensivas em outra frases.Foram testados os bigramas e trigramas com o objetivo de realizar esta verificação de forma adequada e obter melhor performance de classificação, no entanto, verificou-se que o uso de n-gramas mais longos não necessariamente aumenta a precisão do modelo, visto que os resultados foram semelhantes com os 3 tipos. Sendo assim, torna-se preferível a utilização de unigramas, por custarem menos poder de processamento. Observa-se também que a linguagem na Web está sempre repleta de jargões novos, abreviações e erros de gramática, logo, um modelo a ser aplicado neste ambiente deve ser capaz de se adaptar a estas e outras mudanças.

Sobre o discurso de ódio, \textcite{toxist} emprega o uso de Processamento de Linguagem Natural (PLN), fazendo a classificação dos textos, separando-os por índice de toxicidade. Durante o processo de classificação foram comparados diversos modelos diferentes, incluindo o BERT (Bidirectional Encoder Representations from Transformers), XLNet e CNN (Convolutional Neural Network), foi identificada certa superioridade no modelo BERT, empregado agora como o modelo a ser usado definitivamente, por ter se saído melhor na classificação de toxicidade dentro dos textos de forma automática. 

Para testes foram utilizados diferentes tipos de técnicas dentro de cada modelo. Um deles sendo a BoW (Bag of Words), transformando partes do texto em “sacos”, ou seja, conjuntos de palavras sem nexo umas com as outras, e depois conta quantas vezes cada palavra aparece, criando uma matriz onde cada palavra equivale a uma característica, e esta matriz representa a frequência de cada palavra no texto.

De maneira resumida, este projeto tem o objetivo de fazer testes práticos com diferentes modelos de aprendizagem de máquina, a fim de determinar qual teria maior desempenho final e maior precisão na detecção destes comentários. Utilizando de um dataset que possui cerca de 158.640 comentários, durante este projeto, foram extraídos comentários tóxicos e não-tóxicos, fazendo o pré-processamento dos dados em seis etapas, como a \textit{Tokenização}, que é o processo de dividir o texto em partes menores chamadas Tokens, que podem ser números, palavras ou quaisquer símbolos que contenham informação. A segunda etapa consiste na remoção da pontuação e números destes comentários (de forma automática, utilizando PLN), o que torna mais rápido o processamento e aprendizado da Inteligência Artificial (IA). O quarto passo seria chamado de \textit{Stemming}, que consiste em transformar uma palavra para sua forma mais “crua e básica”, como por exemplo a palavra “jogando”, que é uma forma alterada da palavra “jogo”, e é algo que pode ser implementado fazendo uso de algoritmos.  O quinto passo é a correção de palavras com erros gramaticais, substituindo-as pelas palavras corretas. O sexto e último passo é a remoção de certas palavras (neste projeto são chamadas de \textit{Stopwords}, termo em inglês que se refere a palavras que não alteram o sentido geral da frase), com o intuito de diminuir a complexidade destas frases e otimizar o aprendizado da IA.

O estudo possui a finalidade de avaliar o desempenho de diferentes modelos de aprendizado de máquina para a classificação de conteúdo tóxico envolvendo comentários pré-coletados em redes sociais. No presente contexto, depois de fazer o pré-processamento dos dados, a rede neural identifica dentro do dataset todos os comentários tóxicos e não-tóxicos, os categorizando por estes tipos. 

Dos artigos correlatos, este emprega mais similaridade tanto em seu conteúdo-chave (textos com conteúdo de ódio), quanto em sua empregabilidade e processos. A utilização do modelo BERT se tornará indispensável para o andamento do projeto ReSist, assim como o uso de PLN e aprendizagem de máquina na classificação dos textos. 